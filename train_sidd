
import os
import torch
import torch.optim as optim
import torch.nn.functional as F
import torch.nn as nn
from torch.utils.tensorboard import SummaryWriter
import matplotlib.pyplot as plt
from warmup_scheduler import GradualWarmupScheduler
import skimage
from dataloader.data_process_sidd import inv_normalization,write_image
from dataloader.data_loader_sidd import train_dataloader,valid_dataloader
from losses import losses
from tqdm import tqdm
import numpy as np


def _train_sidd(model, args):

    torch.manual_seed(123)
    h_grad = losses.Get_gradient_sobel().to(args.device)
    criterion = torch.nn.L1Loss(reduction='mean').to(args.device)
    # criterion =  torch.nn.MSELoss(reduction='mean').to(args.device)
    # criterion = losses.MS_SSIM_L1_LOSS(args.device)
    # criterion = losses.msssim
 
    optimizer = optim.Adam(model.parameters(),
                                 lr=args.learning_rate,
                                 betas=(0.9, 0.999),
                                 eps=1e-8,
                                 weight_decay=args.weight_decay,
                                 )
    ######### Scheduler-warmup+cosine ###########
   
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.num_epoch, eta_min=1e-6)
   
    # scheduler_cosine = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.num_epoch, eta_min=1e-6)
    # scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=3, after_scheduler=scheduler_cosine)
   
    train_loader = train_dataloader(args.batch_size, args.num_worker)
    max_iter = len(train_loader)
    valida_loader = valid_dataloader( batch_size=1, num_workers=0)
    print(args.ckp, args.num_epoch, args.device)
    try:
            state = torch.load(args.ckp)
            # epoch = state['epoch']
            # optimizer.load_state_dict(state['optimizer'])
            # scheduler.load_state_dict(state['scheduler'])
            # model.load_state_dict(state['model'])
            model.load_state_dict(state, strict=False)
            print('--------------------------train stage-------------------------')
            
    except:
           
            print('-----------------------------ckp faild-----------------------------')
            

  #sony

    # Height = 150
    # Width = 200

    # Height = 128
    # Width = 128

    Height = 512
    Width = 512

    # Height = 712
    # Width = 1064

    best_loss = 0.1
    epoch_loss = []

    for epoch_idx in range(args.num_epoch):
        loss_list = []
      
        model.train()
        for iter_idx, batch_data in tqdm(enumerate(train_loader)):
            input_img, label_img, H, W = batch_data

            input_img = input_img.to(args.device)
            label_img = label_img.to(args.device)

            input_img = input_img.squeeze(dim=1)
            label_img = label_img.squeeze(dim=1)

            for i in range(int(H / Height)):  
                 for j in range(int(W/ Width)):

                    input_patch = input_img[:,:,i * Height:i * Height + Height, j * Width:j * Width + Width]
                    label_patch = label_img[:,:,i * Height:i * Height + Height, j * Width:j * Width + Width]
    
                    pred_patch = model(input_patch)

                    pred_grad = h_grad(pred_patch)
                    label_grad = h_grad(label_patch)

                    # for k in range(len(pred_patch)):

                    #     loss_ini = 0.
                    #     loss_ini += criterion(torch.clamp(pred_patch[k], 0, 1), label_patch)

                    # loss1 = loss_ini / len(pred_patch)
                    
                    loss1 = criterion(torch.clamp(pred_patch, 0, 1), label_patch)
                
                    loss2 = criterion(pred_grad, label_grad)

                    total_loss = 0.8*loss1 + 0.2*loss2
                    loss = total_loss
                    optimizer.zero_grad()
                    total_loss.backward()
                    loss_list.append(loss.item())
                    optimizer.step()
            print(" Epoch: %03d/%03d Iter:%4d/%4d lr: %.6f Loss: %7.6f  \n" % (epoch_idx,args.num_epoch, iter_idx + 1, max_iter, optimizer.param_groups[0]['lr'], loss.item()))
        ave_loss = sum(loss_list) / len(loss_list)
        epoch_loss.append(ave_loss)

        plt.plot(epoch_loss, linewidth=1)
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('training loss curve')
        plt.savefig(os.path.join(args.model_save_dir,'loss_curve.png'))

        scheduler.step()
   
        if best_loss >= ave_loss:
            torch.save(model.state_dict(), os.path.join(args.model_save_dir, args.dataset + '.pth'))
            print('----best_loss = %.6f'%best_loss , 'last_loss = %.6f----' %ave_loss)
            best_loss = ave_loss
        else:
            print('----best_loss = %.6f'%best_loss , 'last_loss = %.6f----' %ave_loss)
            print('.........................Converged...................')

        psnr_list = []
        ssim_list = []
        psnr_ori_list= []
        ssim_ori_list =[]

        with torch.no_grad():

            model.eval()

            print('--------------------------validation stage---------------------')
            for idx, data in enumerate(valida_loader):

                input_img, label_img , _, _ = data

                input_img = input_img.to(args.device)
                label_img = label_img.to(args.device)

                input_img = input_img.squeeze(dim=1)
                label_img = label_img.squeeze(dim=1)

                # i_list = []
                # for i in range(int(H / 189)):
                #     j_list = []
                #     for j in range(int(W / 252)):
                #         input_patch = input_img[:, :, i * Height:i * Height + Height, j * Width:j * Width + Width]
                #         j_list.append(input_patch)
                #     i_list.append(j_list)
                # ii_list = []
                # for i in i_list:
                #     jj_list = []
                #     for j in i:
                #         pred = model(j)
                #         jj_list.append(pred)

                #     ii_list.append(jj_list)
                # pred = torch.zeros(input_img.size())
                
                # for i_index, h in enumerate(ii_list):
                #     for j_index, w in enumerate(h):
                #         pred[:, :, i_index * Height:i_index * Height + Height, j_index * Width:j_index * Width + Width] = w

                pred = model(input_img)
                result_data = pred.cpu().detach().numpy().transpose(0, 2, 3, 1)

                height = result_data.shape[1]
                width = result_data.shape[2]

                result_data = inv_normalization(result_data)
               
                result_write_data = write_image(result_data, height, width)

                input = input_img.cpu().detach().numpy().transpose(0, 2, 3, 1)
              
                input = inv_normalization(input)
              
                input_write_data = write_image(input, height, width)

                gt = label_img.cpu().detach().numpy().transpose(0, 2, 3, 1)
   
                gt = inv_normalization(gt)
        
                gt = write_image(gt, height, width)

                psnr = skimage.metrics.peak_signal_noise_ratio(
                    gt.astype(np.float32), result_write_data.astype(np.float), data_range= 65535)
                ssim = skimage.metrics.structural_similarity(
                    gt.astype(np.float32), result_write_data.astype(np.float),  data_range= 65535)
                
                psnr_list.append(psnr)
                ssim_list.append(ssim)

                orig_psnr = skimage.metrics.peak_signal_noise_ratio(
                    gt.astype(np.float), input_write_data.astype(np.float), data_range= 65535)
                orig_ssim = skimage.metrics.structural_similarity(
                    gt.astype(np.float),  input_write_data.astype(np.float), data_range= 65535)
                
                change_psnr = psnr - orig_psnr
                change_ssim = ssim - orig_ssim

        
                psnr_ori_list.append(orig_psnr)
                ssim_ori_list.append(orig_ssim)

                print('model : %s , dataset: %s \n'%(args.model_name ,args.dataset))
                print('scene:%d' %idx , 'psnr:-----%.4f' %psnr , '-----ssim-----%.4f'%ssim, '-----%.4f' %(orig_psnr), '---%.4f---'%(orig_ssim) , '[%.4f]'%(change_psnr), '[%.4f] \n'%(change_ssim))
 
            ave_psnr = sum(psnr_list) / len(psnr_list)
            ave_ssim = sum(ssim_list) / len(ssim_list)

            ave_orig_psnr = sum( psnr_ori_list) / len( psnr_ori_list)
            ave_orig_ssim = sum( ssim_ori_list ) / len( ssim_ori_list)


            change_ave_psnr = ave_psnr - ave_orig_psnr
            change_ave_ssim = ave_ssim - ave_orig_ssim

            [w, psnr_max, psnr_min, ssim_min] =  [0.8, 60, 30, 0.8]
            score = (w * max(ave_psnr - psnr_min, 0) / (psnr_max - psnr_min) + (1 - w) * max(ave_ssim - ssim_min, 0) / (1 - ssim_min)) * 100

            print('Epoch%03d ----Score:%.4f----PSNR %.4f---SSIM %.4f----orig_psnr --- %.4f ---orig_ssim %.4f ---- , [%.4f] , [%.4f]' % (epoch_idx, score, ave_psnr,ave_ssim , ave_orig_psnr,  ave_orig_ssim ,change_ave_psnr, change_ave_ssim))
      
    save_name = os.path.join(args.model_save_dir, args.dataset + 'final.pth')
    torch.save(model.state_dict(), save_name)


